< [Back](./README.md)  âš¡  [Home](../../README.md)

Note, this document was generated by **Gemini 2.5 Pro (2025-03-25)** and I haven't had time to read much.

# Live Transcription Feature: Implementation Overview

This document provides an overview of the live transcription feature, detailing its core functionality and key components.


## 1. Core Feature: Real-time Speech-to-Text

The live transcription feature enables the application to capture audio from a selected input device in real-time, process it using the Whisper.net library, and display the transcribed text continuously on the console.

**Key capabilities achieved:**

-   Integration of a "Live Transcription" option into the application's menu.
-   Dynamic selection of Whisper models.
-   Cross-platform audio capture through an abstracted service layer.
-   Real-time processing and display of transcribed speech.
-   User control to start and stop transcription.
-   Option to save the full transcription to a file.


## 2. Orchestration and Core Logic: `Workspace.cs`

The `Workspace.cs` class is central to the live transcription process, orchestrating the various components:

-   **Whisper.net Management:**
    -   Loads the selected GGML model file (e.g., `ggml-small.en.bin`).
    -   Initializes the `WhisperFactory` and `WhisperProcessor` from Whisper.net, configured for a target language (typically English).
-   **Audio Service Coordination:**
    -   Detects the operating system (Windows, WSL, Bare-metal Linux).
    -   Instantiates the appropriate platform-specific implementation of `IAudioCaptureService` to handle microphone input.
    -   Manages device selection, allowing the user to choose from available audio input devices.
-   **Real-time Audio Processing Loop (`StartLiveTranscriptionAsync`):**
    -   Subscribes to the `AudioDataAvailable` event from the active `IAudioCaptureService`.
    -   **Buffering:** Incoming raw audio data (16kHz, 16-bit mono PCM) is accumulated into an internal `MemoryStream`. This buffering strategy, configurable by `desiredChunkDurationSeconds` (e.g., 0.75 to 2.5 seconds), helps provide coherent audio segments to Whisper.net.
    -   **Sample Conversion:** When the buffer reaches the `processThresholdInBytes`, the accumulated PCM byte data is converted into an array of `float` samples, normalized to the range `[-1.0, 1.0]`.
    -   **Transcription:** The `float` array of samples is passed to `WhisperProcessor.ProcessAsync()`.
    -   **Event-Driven Output:** As `ProcessAsync` yields transcribed segments:
        -   A `TranscribedDataAvailable` event is raised, passing the transcribed text via `TranscribedDataEventArgs`.
        -   A handler for this event (`HandleTranscribedDataOutput`) writes the text to the console using `AnsiConsole.Write()` for continuous, non-line-broken output.
    -   **User Control:** Monitors for the ESC key press to gracefully stop the transcription.
-   **Resource Management:** Ensures that the audio capture service and Whisper.net components are properly disposed of upon completion or cancellation.


## 3. Audio Input Abstraction: `IAudioCaptureService`

To support multiple platforms, an `IAudioCaptureService` interface defines the contract for audio capture operations. Key elements include:

-   `GetAvailableDevicesAsync()`: Lists available audio input devices.
-   `StartCaptureAsync(string deviceId, WaveFormat waveFormat)`: Begins capturing audio.
-   `StopCaptureAsync()`: Terminates audio capture.
-   `AudioDataAvailable` event: Raised when new audio data is ready.
-   `CurrentWaveFormat` property: Provides the format of the captured audio.

### 3.1. WSL Audio Capture: `WslPulseAudioCaptureService.cs`

This service implements `IAudioCaptureService` specifically for Windows Subsystem for Linux (WSL) environments that use PulseAudio.

-   **Device Discovery:**
    -   Executes the `pactl list sources short` command.
    -   Parses the output to identify available PulseAudio input source names (e.g., `RDPSource`). These are presented to the user for selection.
-   **Audio Capture:**
    -   Uses the `parec` (PulseAudio VRecord) command-line tool.
    -   Constructs the `parec` command with arguments to specify the selected device, and to output raw audio data in the required format (16kHz sample rate, 16-bit little-endian signed PCM, mono). Example: `parec --device=<source_name> --format=s16le --rate=16000 --channels=1 --raw`.
    -   The standard output of the `parec` process, which contains the raw audio stream, is redirected.
-   **Data Handling:**
    -   An asynchronous task reads from `parec`'s redirected output stream into a buffer.
    -   When data is read, the `AudioDataAvailable` event is invoked, providing the audio chunk (as `byte[]`) to `Workspace.cs`.
-   **Process Management:** Handles the starting, stopping (including `Kill` if necessary), and disposal of the `parec` process.


### 3.2. Other Audio Capture Services

Implementations for other platforms also exist:

-   **`WindowsNAudioAudioCaptureService.cs`:** Uses the NAudio library for audio capture on Windows.
-   **`BareMetalAlsaAudioCaptureService.cs`:** Uses `arecord` (ALSA) for audio capture on bare-metal Linux systems.

## 4. User Interaction and Output

-   **Setup:** The user is prompted to select a Whisper model and an audio input device at startup if live transcription is chosen.
-   **Control:** Transcription can be stopped by pressing the ESC key.
-   **Display:** Transcribed text is displayed continuously on the console.
-   **File Saving:** Upon completion, the full transcription is displayed and saved to a text file in the configured output directory (e.g., `LiveTranscript_{Timestamp}_{ModelName}.txt`).

## 5. Key Technical Considerations

-   **Audio Format:** All audio capture services are designed to provide audio data as 16kHz, 16-bit mono PCM, as this is typically expected by Whisper.net for raw sample processing.
-   **Resource Management:** `IDisposable` and `IAsyncDisposable` are used for services and Whisper.net components to ensure proper cleanup.
-   **Buffering Strategy:** The audio buffering in `Workspace.cs` is a key aspect for balancing real-time feel with transcription quality. The `desiredChunkDurationSeconds` constant can be tuned. Shorter durations provide faster feedback but might yield less coherent transcription for some models or quiet audio.
-   **Error Handling:** Basic error handling is in place for common issues like device not found, process failures, and transcription errors.

This revised document aims to provide a clearer understanding of the live transcription feature's architecture and flow.
